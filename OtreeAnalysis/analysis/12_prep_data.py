"""
VMP 2026-02-06 (refactored):

Builds edge tables and interviews metadata from public/distractors_w*.json.
Saves edge CSVs and interviews_w*.csv to public/ folder.

Note: transcripts are generated by 10_create_safe_json.py.
"""

import json
import numpy as np
import pandas as pd
from utilities import wave_2, wave_1, get_public_path

wave = wave_2  # run both wave_1 and wave_2

# --- load from public (sanitized) ---
distractors_path = get_public_path("distractors_w{wave}.json", wave=wave)
with open(distractors_path, "r") as f:
    data = json.load(f)

# --- helper: sort stance_1/stance_2 so edges match across sources ---
def normalize_ab(df, a="stance_1", b="stance_2"):
    df = df.copy()
    df[[a, b]] = np.sort(df[[a, b]].to_numpy(), axis=1)
    return df

# --- canvas edges ---
df_canvas = pd.concat(
    [
        pd.DataFrame(v["edges"]["edges_3"]).assign(key=k).drop(columns="index", errors="ignore")
        for k, v in data.items()
    ],
    ignore_index=True,
).rename(columns={"polarity": "canvas"})

df_canvas = normalize_ab(df_canvas, "stance_1", "stance_2")[["key", "stance_1", "stance_2", "canvas"]]
df_canvas["canvas"] = df_canvas["canvas"].map({"positive": "support", "negative": "conflict"})

# --- pairwise interview edges (wave 2 only) ---
pairwise_rows = []
for k, v in data.items():
    pw = v.get("pairwise_interview")
    if not pw:
        continue
    for entry in pw:
        pair = entry.get("pair", [])
        if len(pair) == 2:
            pairwise_rows.append({
                "key": k,
                "stance_1": pair[0],
                "stance_2": pair[1],
                "pairwise": entry.get("connection_choice"),
            })

if pairwise_rows:
    df_pairwise = pd.DataFrame(pairwise_rows)
    df_pairwise = normalize_ab(df_pairwise, "stance_1", "stance_2")
    df_pairwise = df_pairwise[["key", "stance_1", "stance_2", "pairwise"]]
    df_pairwise["pairwise"] = df_pairwise["pairwise"].replace({"unclear": "no connection"})
else:
    df_pairwise = None

# --- llm edges ---
df_llm = pd.concat(
    [
        pd.DataFrame(v["LLM"]["edge_results"]).assign(key=k).drop(columns="index", errors="ignore")
        for k, v in data.items()
    ],
    ignore_index=True,
)

df_llm = normalize_ab(df_llm, "stance_1", "stance_2")[["key", "stance_1", "stance_2", "polarity"]]
df_llm = df_llm.rename(columns={"polarity": "llm"})
df_llm["llm"] = df_llm["llm"].map({"positive": "support", "negative": "conflict"})
df_llm = df_llm.dropna()  # drops implicit/neutral/etc.

# --- save CSVs to public/ ---
edges_canvas_path = get_public_path(f"edges_canvas_w{wave}.csv")
edges_llm_path = get_public_path(f"edges_llm_w{wave}.csv")

df_canvas.to_csv(edges_canvas_path, index=False)
df_llm.to_csv(edges_llm_path, index=False)

print(f"✓ Saved {len(df_canvas)} canvas edges to {edges_canvas_path}")
print(f"✓ Saved {len(df_llm)} LLM edges to {edges_llm_path}")

if df_pairwise is not None:
    edges_pairwise_path = get_public_path(f"edges_pairwise_w{wave}.csv")
    df_pairwise.to_csv(edges_pairwise_path, index=False)
    print(f"✓ Saved {len(df_pairwise)} pairwise edges to {edges_pairwise_path}")

# --- interviews metadata (from interview_metadata added during sanitization) ---
interview_rows = []
for k, v in data.items():
    for entry in (v.get("interview_metadata") or []):
        interview_rows.append({"key": k, **entry})

if interview_rows:
    df_interviews = pd.DataFrame(interview_rows)
    interviews_path = get_public_path(f"interviews_w{wave}.csv")
    df_interviews.to_csv(interviews_path, index=False)
    print(f"✓ Saved {len(df_interviews)} interview rows to {interviews_path}")